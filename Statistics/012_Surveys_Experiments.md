# Surveys & Experiments

In the previous section, [[011_Data Types]] we saw what to measure. Now, we see the second part, which is how to measure. 

## How to Measure? 

In order to test the hypothesis, we need to reliably measure variables. Now we are going to see how to measure variables. In a very broad sense, there are two ways of testing the hypothesis: 

1. Observing what naturally happens without directly interfering with it. This is known as [[Observational study]] or **cross-sectional research**. It is also called **correlational research**. 
2. Manipulating some aspect of the environment and observing the effects it has on the variable of interest. This is known as [[experimental research]]. 

### Experimental Research

In experimental research we look at the causal connection between an independent variable or variables and the dependent variable or **outcome variable**. Sometimes the causal link is evident but sometimes it is subtle. In order to infer causality:

1. Cause and effect must occur close together in time
2. The cause must occur first before the effect
3. The effect must not occur without the presence of a cause
4. The effect should be present when the cause is present and when the cause is absent, the effect must be absent. (condition to remove confounding variable)

Somtimes there is no direct connection between an indepedent variable and a dependent variable. A third variable [[confounding variable]] influences the dependent variable. With the above found conditions, we can find a causal link between the independent and dependent variable. 

The four conditions are put into practice in experimental research with the use of **control **and **treatment** groups. These two groups allow to root out any confounding variables. However, depending on the values a variable takes we may need to use more groups. For example, if we wish to test the effect motivators have on learning, we see that the variable, motivation takes on three values: postive, negative, and neutral. So, in this case, we will have three groups. 

> In correlational research, we observe the co-occurrence of variables. We do not manipulate the cause first to measure the effect, therefore we cannot compare the effect when the causal variable is present against when it is absent. In other words, we cannot say which variable causes a change in the other, we can only say that variables co-occur in a certain way. 

In experimental research, there are two ways of collecting data. These are: 

1. Manipulate independent variable on different groups. This is known as **between-groups**, **between-subjects** or **independent design**. 
2. Manipulate the independent variable on the same group. This is known as **within-subjects** or **repeated-measures design**

> The way in which the data are collected determines the type of test that is used to analyse the data. 

The two figures below summarize an experiment and an observational study: 

![[Pasted image 20210318095736.png]]

![[Pasted image 20210318095749.png]]


### Two Types of Variation

When it comes to measurement error, we have two types:

* Variation in measurements due to human error or an instrument is known as **systematic error** 
* Variation due to factors that are beyond our control is known as **unsystematic error**. 

> The role of statistics is to discover how much variation there is in performance, and then to work out how much of this is systematic and how much is unsystematic. 

Let's look at the variations in independent design and repeated-measures design: 

* In repeated-measures design, the differences between two conditions can be caused by only two things: (1) the manipulation that was carried out on the participants by the experimenter, or (2) factors pertaining to the performance of the participant from one time to the next. The later factor is smaller compared to the former.

* In independent design, the difference between two conditions can be caused by two things: (1) the manipulation that was carried out on the participants by the experimenter or (2) differences in the characteristics of the participants between two groups.

Because the factor in repeated-measures design is generally small, the effect due to manipulation is greater. However, this is not the case in independent design because the second factor is not always negligible unless care is taken. Therefore, everything being equal, the repeated-measures design have more power to detect effects than independent designs. 

## Randomization

In general, if we keep the unsystematic error to the minimum, which is often the noise, we are more sensitive to effects caused by manipulation. Therefore, it is important to keep both systematic and unsystematic error to the minimum. 

One way to achieve the reduction of systematic error is through [[randomization]]. Let's see how we can use randomization in independent and repeated-measures design:

Repeated-measures Design: In this category, the participants have no knowledge of the experiment the first time they participate in. However, during the second time they have some knowledge. The two sources of systematic variation in this design type are: 
* Practice effects - this is due to familiarity with the experimental situation
* Boredom effects - participants will not perform optimally because they are either tired or bored

To counter this, we randomize the order in which the participants perform tasks. If there are two tasks to be performed, then some participants performs 1 and then 2 while others perform 2 and then 1. 

In the independent design, we randomly allocate participants to either the control or the treatment group. This ensures that confounding variables are evenly distributed across conditions. 


